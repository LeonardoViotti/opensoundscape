{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction\n",
    "\n",
    "This notebook downloads an example baseline model. All baseline models are available [here](https://pitt.box.com/s/a6jeamnew098vp5a9a7m1h9j5rce6t6y) although they are beta models and not recommended for research use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#import modules from Opensoundscape\n",
    "from opensoundscape.torch.predict import predict\n",
    "from opensoundscape.datasets import SingleTargetAudioDataset\n",
    "from opensoundscape.helpers import run_command\n",
    "from opensoundscape.datasets import SplitterDataset\n",
    "from opensoundscape.raven import lowercase_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torchvision.models\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model\n",
    "Download the example model for Wood Thrush, *Hylocichla mustelina*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_box(link, name):\n",
    "    run_command(f\"curl -L {link} -o ./{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"prediction_example\"\n",
    "folder_path = Path(folder_name)\n",
    "if not folder_path.exists(): folder_path.mkdir()\n",
    "model_filename = folder_path.joinpath(\"hylocichla-mustelina-epoch-4.model\")\n",
    "download_from_box(\n",
    "    link = \"https://pitt.box.com/shared/static/dslgslmag7y8ojqxv28mwhbnt7irpgeo.model\",\n",
    "    name = model_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "The model must be loaded with the same specifications that it was created with: a combination of a `resnet18` convolutional neural network and a `Linear` classifier. This model predicts two \"classes\": the presence and absence of Wood Thrush."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "#model.load_state_dict(torch.load(\"scolopax-minor-epoch-4.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare prediction files\n",
    "\n",
    "Download an example soundscape which contains Wood Thrush vocalizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = folder_path.joinpath(\"1min.wav\")\n",
    "download_from_box(\n",
    "    link = \"https://pitt.box.com/shared/static/z73eked7quh1t2pp93axzrrpq6wwydx0.wav\",\n",
    "    name = data_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "The example soundscape must be split up into soundscapes of the same size as the ones the model was trained on. In this case, the soundscapes should be 5s long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_split = [data_filename]\n",
    "split_directory = folder_path.joinpath(\"split_files\")\n",
    "if not split_directory.exists(): split_directory.mkdir()\n",
    "dataset = SplitterDataset(\n",
    "    files_to_split,\n",
    "    overlap=0,\n",
    "    duration=5,\n",
    "    output_directory=split_directory,\n",
    "    include_last_segment=True\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=SplitterDataset.collate_fn,\n",
    ")\n",
    "\n",
    "results_csv = folder_path.joinpath(\"prediction_files.csv\")\n",
    "with open(results_csv, \"w\") as f:\n",
    "    if False:\n",
    "        f.write(\"Source,Annotations,Begin (s),End (s),Destination,Labels\\n\")\n",
    "    else:\n",
    "        f.write(\"Source,Begin (s),End (s),Destination\\n\")\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        for output in data:\n",
    "            f.write(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset\n",
    "\n",
    "Create a dataset from these data. We create a dictionary that associates numeric labels with the class names: 1 is for predicting a Wood Thrush's presence; 0 is for predicting a Wood Thrush's absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_analyze=list(split_directory.glob(\"*.wav\"))\n",
    "sample_df = pd.DataFrame(columns=['file'],data=files_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0:'absent', 1:'hylocichla-mustelina'}\n",
    "test_dataset = SingleTargetAudioDataset(\n",
    "    sample_df,\n",
    "    filename_column = \"file\",\n",
    "    label_dict = label_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model on prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absent</th>\n",
       "      <th>hylocichla-mustelina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/bc645003351149f4a7e2c7109b22afc1.wav</th>\n",
       "      <td>0.816133</td>\n",
       "      <td>-0.903320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/e36a0f200cdf42a23d49e78445121387.wav</th>\n",
       "      <td>1.480433</td>\n",
       "      <td>-0.927409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/4940c91a1837410240042cf55ccad568.wav</th>\n",
       "      <td>1.940377</td>\n",
       "      <td>-1.725088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/cfc05bd9e1b97eebdca3badc288de0cd.wav</th>\n",
       "      <td>2.629047</td>\n",
       "      <td>-1.988923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/32747f95e81ee34c56ed177c4f7e7df5.wav</th>\n",
       "      <td>2.513747</td>\n",
       "      <td>-2.366485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/369134205221b5a25fac0e264d0a1482.wav</th>\n",
       "      <td>2.351259</td>\n",
       "      <td>-1.628652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/f3d6aeabe7725f649dc56d6db04aa83f.wav</th>\n",
       "      <td>1.570931</td>\n",
       "      <td>-1.124706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/54534197c0768b6bb2a9305013e8c1af.wav</th>\n",
       "      <td>1.744635</td>\n",
       "      <td>-1.055664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/e0c2d4aed1d79d4a6194be948d3292da.wav</th>\n",
       "      <td>1.315882</td>\n",
       "      <td>-1.407135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/9d276a5dd54b631c4aa63da407a1225d.wav</th>\n",
       "      <td>1.766514</td>\n",
       "      <td>-1.096341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/636f23557581b700f286b7db29d01b61.wav</th>\n",
       "      <td>0.273381</td>\n",
       "      <td>-0.397208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_example/split_files/e55ba1b5a1316fcda5f3b4d73b2e36ee.wav</th>\n",
       "      <td>2.138355</td>\n",
       "      <td>-1.632506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      absent  \\\n",
       "prediction_example/split_files/bc645003351149f4...  0.816133   \n",
       "prediction_example/split_files/e36a0f200cdf42a2...  1.480433   \n",
       "prediction_example/split_files/4940c91a18374102...  1.940377   \n",
       "prediction_example/split_files/cfc05bd9e1b97eeb...  2.629047   \n",
       "prediction_example/split_files/32747f95e81ee34c...  2.513747   \n",
       "prediction_example/split_files/369134205221b5a2...  2.351259   \n",
       "prediction_example/split_files/f3d6aeabe7725f64...  1.570931   \n",
       "prediction_example/split_files/54534197c0768b6b...  1.744635   \n",
       "prediction_example/split_files/e0c2d4aed1d79d4a...  1.315882   \n",
       "prediction_example/split_files/9d276a5dd54b631c...  1.766514   \n",
       "prediction_example/split_files/636f23557581b700...  0.273381   \n",
       "prediction_example/split_files/e55ba1b5a1316fcd...  2.138355   \n",
       "\n",
       "                                                    hylocichla-mustelina  \n",
       "prediction_example/split_files/bc645003351149f4...             -0.903320  \n",
       "prediction_example/split_files/e36a0f200cdf42a2...             -0.927409  \n",
       "prediction_example/split_files/4940c91a18374102...             -1.725088  \n",
       "prediction_example/split_files/cfc05bd9e1b97eeb...             -1.988923  \n",
       "prediction_example/split_files/32747f95e81ee34c...             -2.366485  \n",
       "prediction_example/split_files/369134205221b5a2...             -1.628652  \n",
       "prediction_example/split_files/f3d6aeabe7725f64...             -1.124706  \n",
       "prediction_example/split_files/54534197c0768b6b...             -1.055664  \n",
       "prediction_example/split_files/e0c2d4aed1d79d4a...             -1.407135  \n",
       "prediction_example/split_files/9d276a5dd54b631c...             -1.096341  \n",
       "prediction_example/split_files/636f23557581b700...             -0.397208  \n",
       "prediction_example/split_files/e55ba1b5a1316fcd...             -1.632506  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "prediction_df = predict(model, test_dataset, label_dict=label_dict)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command \"cleans up\" by deleting all the downloaded files and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensoundscape (poetry)",
   "language": "python",
   "name": "opensoundscape-6-tandav-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
