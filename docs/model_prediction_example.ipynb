{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a model to predict contents of an audio file\n",
    "\n",
    "This notebook downloads an example baseline model. All baseline models are available [here](https://pitt.box.com/s/a6jeamnew098vp5a9a7m1h9j5rce6t6y) although they are beta models and not recommended for research use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tessa/Library/Caches/pypoetry/virtualenvs/opensoundscape-dxMTH98s-py3.7/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/tessa/Library/Caches/pypoetry/virtualenvs/opensoundscape-dxMTH98s-py3.7/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "from opensoundscape.torch.predict import predict\n",
    "from opensoundscape.datasets import SingleTargetAudioDataset\n",
    "from opensoundscape.helpers import run_command\n",
    "from opensoundscape.datasets import SplitterDataset\n",
    "from opensoundscape.raven import lowercase_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torchvision.models\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model\n",
    "Download the example model for Wood Thrush, *Hylocichla mustelina*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_box(link, name):\n",
    "    run_command(f\"curl -L {link} -o ./{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"prediction_example\"\n",
    "folder_path = Path(folder_name)\n",
    "if not folder_path.exists(): folder_path.mkdir()\n",
    "model_filename = folder_path.joinpath(\"hylocichla-mustelina-epoch-4.model\")\n",
    "download_from_box(\n",
    "    link = \"https://pitt.box.com/shared/static/dslgslmag7y8ojqxv28mwhbnt7irpgeo.model\",\n",
    "    name = model_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "The model must be loaded with the same specifications that it was created with: a combination of a `resnet18` convolutional neural network and a `Linear` classifier. This model predicts two \"classes\": the presence and absence of Wood Thrush."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "#model.load_state_dict(torch.load(\"scolopax-minor-epoch-4.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prediction files\n",
    "\n",
    "Download an example soundscape which contains Wood Thrush vocalizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = folder_path.joinpath(\"1min.wav\")\n",
    "download_from_box(\n",
    "    link = \"https://pitt.box.com/shared/static/z73eked7quh1t2pp93axzrrpq6wwydx0.wav\",\n",
    "    name = data_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split file\n",
    "The example soundscape must be split up into soundscapes of the same size as the ones the model was trained on. In this case, the soundscapes should be 5s long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a237a5d31858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles_to_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_filename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msplit_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"split_files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m dataset = SplitterDataset(\n\u001b[1;32m      5\u001b[0m     \u001b[0mfiles_to_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_directory' is not defined"
     ]
    }
   ],
   "source": [
    "files_to_split = [data_filename]\n",
    "split_directory = folder_path.joinpath(\"split_files\")\n",
    "if not output_directory.exists(): output_directory.mkdir()\n",
    "dataset = SplitterDataset(\n",
    "    files_to_split,\n",
    "    overlap=0,\n",
    "    duration=5,\n",
    "    output_directory=split_directory,\n",
    "    include_last_segment=True\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=SplitterDataset.collate_fn,\n",
    ")\n",
    "\n",
    "results_csv = folder_path.joinpath(\"prediction_files.csv\")\n",
    "with open(results_csv, \"w\") as f:\n",
    "    if False:\n",
    "        f.write(\"Source,Annotations,Begin (s),End (s),Destination,Labels\\n\")\n",
    "    else:\n",
    "        f.write(\"Source,Begin (s),End (s),Destination\\n\")\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        for output in data:\n",
    "            f.write(f\"{output}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data\n",
    "\n",
    "Create a dataset from these data. We create a dictionary that associates numeric labels with the class names: 1 is for predicting a Wood Thrush's presence; 0 is for predicting a Wood Thrush's absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_analyze=list(split_directory.glob(\"*.wav\"))\n",
    "sample_df = pd.DataFrame(columns=['file'],data=files_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0:'absent', 1:'hylocichla-mustelina'}\n",
    "test_dataset = SingleTargetAudioDataset(\n",
    "    sample_df,\n",
    "    filename_column = \"file\",\n",
    "    label_dict = label_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model on prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prediction_df = predict(model, test_dataset, label_dict=label_dict)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up when finished\n",
    "\n",
    "This command \"cleans up\" by deleting all the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape",
   "language": "python",
   "name": "opensoundscape-dxmth98s-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
