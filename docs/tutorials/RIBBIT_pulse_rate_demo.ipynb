{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIBBIT Pulse Rate model demonstration\n",
    "RIBBIT (Repeat-Interval Based Bioacoustic Identification Tool) is a tool for detecting vocalizations that have a repeating structure.\n",
    "\n",
    "This tool is useful for detecting vocalizations of frogs, toads, and other animals that produce vocalizations with a periodic structure. In this notebook, we demonstrate how to select model parameters for the Great Plains Toad, then run the model on data to detect vocalizations.\n",
    "\n",
    "This work is described in:\n",
    "\n",
    "* 2021 paper, [\"Automated detection of frog calls and choruses by pulse repetition rate\"](https://doi.org/10.1111/cobi.13718)\n",
    "\n",
    "* 2020 poster, [\"Automatic Detection of Pulsed Vocalizations\"](https://f1000research.com/posters/9-964)\n",
    "\n",
    "RIBBIT is also [available as an R package](https://github.com/kitzeslab/r-ribbit).\n",
    "\n",
    "This notebook demonstrates how to use the RIBBIT tool implemented in opensoundscape as `opensoundscape.ribbit.ribbit()`\n",
    "\n",
    "For help instaling OpenSoundscape, see the [documentation](https://opensoundscape.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#import packages\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "#local imports from opensoundscape\n",
    "from opensoundscape.audio import Audio\n",
    "from opensoundscape.spectrogram import Spectrogram\n",
    "from opensoundscape.ribbit import ribbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display settings\n",
    "plt.rcParams['figure.figsize']=[15,8] \n",
    "pd.set_option('display.precision', 2)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download example audio\n",
    "\n",
    "First, let's download some example audio to work with.\n",
    "\n",
    "You can run the cell below, **OR** visit this link to downlaod the data (whichever you find easier):\n",
    "\n",
    "https://pitt.box.com/shared/static/0xclmulc4gy0obewtzbzyfnsczwgr9we.zip\n",
    "\n",
    "If you download using the link above, first un-zip the folder (double-click on mac or right-click -> extract all on Windows). Then, move the `great_plains_toad_dataset` folder to the same location on your computer as this notebook. Then you can skip this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download files from box.com to the current directory\n",
    "subprocess.run(['curl', 'https://drive.google.com/uc?export=download&id=1Zjeyp6Zjdk0zugK9jhfBIuWHE__a0SKu','-L', '-o', 'great_plains_toad_dataset.tar.gz']) # Download the data\n",
    "subprocess.run([\"tar\",\"-xzf\", \"great_plains_toad_dataset.tar.gz\"]) # Unzip the downloaded tar.gz file\n",
    "subprocess.run([\"rm\", \"great_plains_toad_dataset.tar.gz\"]) # Remove the file after its contents are unzipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, you should have a folder in the same location as this notebook called `great_plains_toad_dataset`\n",
    "\n",
    "if you had trouble accessing the data, you can try using your own audio files - just put them in a folder called `great_plains_toad_dataset` in the same location as this notebook, and this notebook will load whatever is in that folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an audio file and create a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = np.sort(glob('./great_plains_toad_dataset/*'))[0]\n",
    "\n",
    "#load the audio file into an OpenSoundscape Audio object\n",
    "audio = Audio.from_file(audio_path)\n",
    "\n",
    "#trim the audio to the time from 0-3 seconds for a closer look\n",
    "audio = audio.trim(0,3)\n",
    "\n",
    "#create a Spectrogram object\n",
    "spectrogram = Spectrogram.from_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the Great Plains Toad spectrogram as an image\n",
    "A spectrogram is a visual representation of audio with frequency on the vertical axis, time on the horizontal axis, and intensity represented by the color of the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select model parameters\n",
    "\n",
    "RIBBIT requires the user to select a set of parameters that describe the target vocalization. Here is some detailed advice on how to use these parameters.\n",
    "\n",
    "**Signal Band:** The signal band is the frequency range where RIBBIT looks for the target species. Based on the spectrogram above, we can see that the Great Plains Toad vocalization has the strongest energy around 2000-2500 Hz, so we will specify `signal_band = [2000,2500]`. It is best to pick a narrow signal band if possible, so that the model focuses on a specific part of the spectrogram and has less potential to include erronious sounds. \n",
    "\n",
    "**Noise Bands:** Optionally, users can specify other frequency ranges called noise bands. Sounds in the `noise_bands` are _subtracted_ from the `signal_band`. Noise bands help the model filter out erronious sounds from the recordings, which could include confusion species, background noise, and popping/clicking of the microphone due to rain, wind, or digital errors. It's usually good to include one noise band for very low frequencies -- this specifically eliminates popping and clicking from being registered as a vocalization. It's also good to specify noise bands that target confusion species. Another approach is to specify two narrow `noise_bands` that are directly above and below the `signal_band`. \n",
    "\n",
    "**Pulse Rate Range:** This parameters specifies the minimum and maximum pulse rate (the number of pulses per second, also known as pulse repetition rate) RIBBIT should look for to find the focal species. Looking at the spectrogram above, we can see that the pulse rate of this Great Plains Toad vocalization is about 15 pulses per second. By looking at other vocalizations in different environmental conditions, we notice that the pulse rate can be as slow as 10 pulses per second or as fast as 20. So, we choose `pulse_rate_range = [10, 20]` meaning that RIBBIT should look for pulses no slower than 10 pulses per second and no faster than 20 pulses per second. \n",
    "\n",
    "**Clip Duration:** This parameter tells the algorithm how many seconds of audio to analyze at one time. Generally, you should choose a `clip_duration` that is ~2x longer than the target species vocalization, or a little bit longer. For very slowly pulsing vocalizations, choose a longer window so that at least 5 pulses can occur in one window (0.5 pulses per second -> 10 second window). Typical values for `clip_duration` are 0.3 to 10 seconds. Here, because the The Great Plains Toad has a vocalization that continues on for many seconds (or minutes!), we chose a 2-second window which will include plenty of pulses. \n",
    "\n",
    "- we can also set `clip_overlap` if we want overlapping clips. For instance, a `clip_duration` of 2 with `clip_overlap` of 1 results in 50% overlap of each consecutive clip. This can help avoid sounds being split up across two clips, and therefore not being detected. \n",
    "- `final_clip` determines what should be done when there is less than `clip_duration` audio remaining at the end of an audio file. We'll just use `final_clip=None` to discard any remaining audio that doesn't make a complete clip. \n",
    "\n",
    "**Plot:** We can choose to show the power spectrum of pulse repetition rate for each window by setting `plot=True`. The default is not to show these plots (`plot=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum and maximum rate of pulsing (pulses per second) to search for\n",
    "pulse_rate_range = [8,15] \n",
    "\n",
    "# look for a vocalization in the range of 1000-2000 Hz \n",
    "signal_band = [1800,2400] \n",
    "\n",
    "# subtract the amplitude signal from these frequency ranges\n",
    "noise_bands = [ [0,1000], [3000,3200] ] \n",
    "\n",
    "#divides the signal into segments this many seconds long, analyzes each independently\n",
    "clip_duration = 2 #seconds\n",
    "clip_overlap = 0 #seconds\n",
    "\n",
    "#if True, it will show the power spectrum plot for each audio segment \n",
    "show_plots = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for pulsing vocalizations with `ribbit()` \n",
    "\n",
    "This function takes the parameters we chose above as arguments, performs the analysis, and returns two arrays:\n",
    " - **scores:** the pulse rate score for each window\n",
    " - **times:** the start time in seconds of each window\n",
    " \n",
    "The scores output by the function may be very low or very high. They do not represent a \"confidence\" or \"probability\" from 0 to 1. Instead, the relative values of scores on a set of files should be considered: when RIBBIT detects the target species, the scores will be significantly higher than when the species is not detected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing one file\n",
    "The file `gpt0.wav` has a Great Plains Toad vocalizing only at the beginning. Let's analyze the file with RIBBIT and look at the scores versus time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the audio file path\n",
    "audio_path = np.sort(glob('./great_plains_toad_dataset/*'))[0]\n",
    "\n",
    "#make the spectrogram\n",
    "spec = Spectrogram.from_audio(audio.from_file(audio_path))\n",
    "\n",
    "#run RIBBIT\n",
    "score_df =  ribbit(\n",
    "                    spec,\n",
    "                    pulse_rate_range=pulse_rate_range,\n",
    "                    signal_band=signal_band,\n",
    "                    clip_duration=clip_duration,\n",
    "                    noise_bands=noise_bands,\n",
    "                    plot=False\n",
    ")\n",
    "\n",
    "\n",
    "#show the spectrogram\n",
    "print('spectrogram of 10 second file with Great Plains Toad at the beginning')\n",
    "spec.plot()\n",
    "\n",
    "# plot the score vs time of each window\n",
    "plt.scatter(score_df['start_time'],score_df['score'])\n",
    "plt.xlabel('window start time (sec)')\n",
    "plt.ylabel('RIBBIT score')\n",
    "plt.title('RIBBIT scores for 10 second file with Great Plains Toad at the beginning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we hoped, RIBBIT outputs a high score during the vocalization (the window from 0-2 seconds) and a low score when the frog is not vocalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing a set of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dataframe for storing files' scores and labels\n",
    "df = pd.DataFrame(index = glob('./great_plains_toad_dataset/*'),columns=['score','label'])\n",
    "\n",
    "# label is 1 if the file contains a Great Plains Toad vocalization, and 0 if it does not\n",
    "df['label'] = [1 if 'gpt' in f else 0 for f in df.index] \n",
    "\n",
    "# calculate RIBBIT scores\n",
    "for path in df.index:\n",
    "    \n",
    "    #make the spectrogram\n",
    "    spec = Spectrogram.from_audio(audio.from_file(path))\n",
    "\n",
    "    #run RIBBIT\n",
    "    score_df =  ribbit(\n",
    "                        spec,\n",
    "                        pulse_rate_range=[8,20],\n",
    "                        signal_band=[1900,2400],\n",
    "                        clip_duration=clip_duration,\n",
    "                        noise_bands=[[0,1500],[2500,3500]],\n",
    "                        plot=False)\n",
    "    \n",
    "    # use the maximum RIBBIT score from any window as the score for this file\n",
    "    # multiply the score by 10,000 to make it easier to read\n",
    "    df.at[path,'score'] = max(score_df['score']) * 10000\n",
    "\n",
    "print(\"Files sorted by score, from highest to lowest:\")\n",
    "df.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how good is RIBBIT at finding the Great Plains Toad?\n",
    "\n",
    "We can see that the scores for all of the files with Great Plains Toad (gpt) score above 10 except `gpt4.wav` (which contains only a very quiet and distant vocalization). All files that do not contain the Great Plains Toad score less than 3.5. So, RIBBIT is doing a good job separating Great Plains Toads vocalizations from other sounds! \n",
    "\n",
    "Notably, noisy files like `pops1.wav` score low even though they have lots of periodic energy - our `noise_bands` sucessfully rejected these files. Without using `noise_bands`, files like these would receive very high scores. Also, some birds in \"negatives\" files  that have periodic calls around the same pulse rate as the Great Plains Toad received low scores. This is also a result of choosing a tight `signal_band` and strategic `noise_bands`. You can try adjusting or eliminating these bands to see their effect on the audio. \n",
    "\n",
    "(HINT: eliminating the `noise_bands` will result in high scores for the \"pops\" files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RIBBIT on multiple species simultaneously\n",
    "\n",
    "If you want to search for multiple species, its best to combine the analysis into one function - that way you only have to load each audio file (and make it's spectrogram) one time, instead of once for each species. (If you have thousands of audio files, this might be a big time saver.) \n",
    "\n",
    "This code gives a quick exmaple of how you could use a pre-made dataframe (could load it in from a spreadsheet, for instance) of parameters for a set of species to run RIBBIT on all of them.\n",
    "\n",
    "Note that this example assumes you are using the same spectrogram settings for each species - this might not be the case in practice, if some species require high time-resolution spectrograms and others require high frequency-resolution spectrograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll create a dataframe here, but you could also load it from a spreadsheet\n",
    "species_df = pd.DataFrame(columns=['pulse_rate_range','signal_band','clip_duration','noise_bands'])\n",
    "\n",
    "species_df.loc['great_plains_toad']={\n",
    "    'pulse_rate_range':[8,20],\n",
    "    'signal_band':[1900,2400],\n",
    "    'clip_duration':2.0,\n",
    "    'noise_bands':[[0,1500],[2500,3500]]\n",
    "}\n",
    "\n",
    "species_df.loc['bird_series']={\n",
    "    'pulse_rate_range':[8,11],\n",
    "    'signal_band':[5000,6500],\n",
    "    'clip_duration':2.0,\n",
    "    'noise_bands':[[0,4000]]\n",
    "}\n",
    "\n",
    "\n",
    "species_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's analyze each audio file for each species. \n",
    "\n",
    "We'll save the results in a table that has a column for each species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dataframe for storing files' scores and labels\n",
    "df = pd.DataFrame(index = glob('./great_plains_toad_dataset/*'),columns=species_df.index.values)\n",
    "\n",
    "# calculate RIBBIT scores\n",
    "for path in df.index:\n",
    "    \n",
    "    for species, species_params in species_df.iterrows():\n",
    "    #use RIBBIT for each species in species_df \n",
    "        #make the spectrogram\n",
    "        spec = Spectrogram.from_audio(audio.from_file(path))\n",
    "\n",
    "        #run RIBBIT\n",
    "        score_df =  ribbit(\n",
    "                            spec,\n",
    "                            pulse_rate_range=species_params['pulse_rate_range'],\n",
    "                            signal_band=species_params['signal_band'],\n",
    "                            clip_duration=species_params['clip_duration'],\n",
    "                            noise_bands=species_params['noise_bands'],\n",
    "                            plot=False)\n",
    "\n",
    "        # use the maximum RIBBIT score from any window as the score for this file\n",
    "        # multiply the score by 10,000 to make it easier to read\n",
    "        df.at[path,species] = max(score_df['score']) * 10000\n",
    "\n",
    "print(\"Files with scores for each species, sorted by 'bird_series' score:\")\n",
    "df.sort_values(by='bird_series',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at the highest scoring file for 'bird_series', it has the trilled bird sound at 5-6.5 kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectrogram.from_audio(audio.from_file('./great_plains_toad_dataset/negative5.wav')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "when loading a dataframe from a file, lists of numbers like [8,20] might be read in as strings (\"[8,20]\") rather than a list of numbers. \n",
    "Here's a handy little piece of code that will load the values in the desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's say we have the species df saved as a csv file\n",
    "species_df.index.name='species'\n",
    "species_df.to_csv('species_df.csv')\n",
    "\n",
    "#define the conversion parameters for each column\n",
    "import ast\n",
    "generic = lambda x: ast.literal_eval(x)\n",
    "conv = {\n",
    "    'pulse_rate_range':generic,\n",
    "    'signal_band':generic,\n",
    "    'noise_bands':generic\n",
    "}\n",
    "#tell pandas to use them when loading the csv\n",
    "species_df=pd.read_csv('./species_df.csv',converters=conv).set_index('species')\n",
    "\n",
    "#now the species_df has numeric values instead of strings\n",
    "species_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail view of RIBBIT method\n",
    "Now, let's look at one 10 second file and tell ribbit to plot the power spectral density for each window (`plot=True`). This way, we can see if peaks are emerging at the expected pulse rates. Since our `window_length` is 2 seconds, each of these plots represents 2 seconds of audio. The vertical lines on the power spectral density represent the lower and upper `pulse_rate_range` limits. \n",
    "\n",
    "In the file `gpt0.wav`, the Great Plains Toad vocalizes for a couple seconds at the beginning, then stops. We expect to see a peak in the power spectral density at 15 pulses/sec in the first 2 second window, and maybe a bit in the second, but not later in the audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spectrogram from the file, like above:\n",
    "# 1. get audio file path\n",
    "audio_path = np.sort(glob('./great_plains_toad_dataset/*'))[0]\n",
    "# 2. make audio object and trim (this time 0-10 seconds)\n",
    "audio = Audio.from_file(audio_path).trim(0,10)\n",
    "# 3. make spectrogram\n",
    "spectrogram = Spectrogram.from_audio(audio)\n",
    "\n",
    "clip_df =  ribbit(\n",
    "                        spectrogram,\n",
    "                        pulse_rate_range=pulse_rate_range,\n",
    "                        signal_band=signal_band,\n",
    "                        clip_duration=clip_duration,\n",
    "                        noise_bands=noise_bands,\n",
    "                        plot=show_plots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to experiment for yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the basics of how to use RIBBIT, you can try using it on your own data. We recommend spending some time looking at different recordings of your focal species before choosing parameters. Experiment with the noise bands and window length, and get in touch if you have questions!\n",
    "\n",
    "Sam's email: sam . lapp [at] pitt.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up\n",
    "this cell will delete the folder `great_plains_toad_dataset`. Only run it if you wish delete that folder and the example audio inside it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "shutil.rmtree('./great_plains_toad_dataset/')\n",
    "Path('./species_df.csv').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
