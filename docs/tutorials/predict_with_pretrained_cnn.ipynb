{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with pre-trained CNNs\n",
    "This notebook contains all the code you need to use a pre-trained OpenSoundscape convolutional neural network model (CNN) to make predictions on your own data. Before attempting this tutorial, install OpenSoundscape by following the instructions on the OpenSoundscape website, [opensoundscape.org](http://opensoundscape.org/). More detailed tutorials about data preprocessing, training CNNs, and customizing prediction methods can also be found on this site.\n",
    "\n",
    "Note that prediction no longer requires you to split your files into clips ahead of time - you can simply create a list of audio files of arbitrary length. Prediction scores will be generated on windows of a fixed length, eg 5 seconds, for the duration of each audio file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cnn` module provides a function `load_model` to load saved opensoundscape models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.torch.models.cnn import load_model, load_outdated_model\n",
    "import opensoundscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load some additional packages and perform some setup for the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other utilities and packages\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up plotting\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, let's create an untrained model and save it. This 2-class model is not actually good at recognizing any particular species, but it's useful for illustrating how prediction works. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.torch.models.cnn import CNN\n",
    "CNN('resnet18',['classA','classB'],5.0).save('./temp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model object using the `load_model` function imported above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./temp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose audio files for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of audio files to predict on. They can be of any length. Consider using `glob` to find many files at once.\n",
    "\n",
    "For this example, let's download a 1-minute audio clip from the Kitzes Lab box to use as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     7    0     7    0     0      5      0 --:--:--  0:00:01 --:--:--     0\n",
      "100 3750k  100 3750k    0     0  1396k      0  0:00:02  0:00:02 --:--:-- 3446k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['curl', 'https://pitt.box.com/shared/static/z73eked7quh1t2pp93axzrrpq6wwydx0.wav', '-L', '-o', '1min_audio.wav'], returncode=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['curl',\n",
    "               'https://pitt.box.com/shared/static/z73eked7quh1t2pp93axzrrpq6wwydx0.wav', \n",
    "                '-L', '-o', '1min_audio.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./1min_audio.wav']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob \n",
    "audio_files = glob('./*.wav') #match all .wav files in the current directory\n",
    "audio_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate predictions with the model\n",
    "The model returns a dataframe with a MultiIndex of file, start_time, and end_time. There is one column for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>classA</th>\n",
       "      <th>classB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">./1min_audio.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>-0.014681</td>\n",
       "      <td>0.394269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.162471</td>\n",
       "      <td>0.223495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>15.0</th>\n",
       "      <td>-0.412240</td>\n",
       "      <td>0.413294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <th>20.0</th>\n",
       "      <td>-0.089480</td>\n",
       "      <td>0.528132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <th>25.0</th>\n",
       "      <td>-0.214247</td>\n",
       "      <td>0.450105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        classA    classB\n",
       "file             start_time end_time                    \n",
       "./1min_audio.wav 0.0        5.0      -0.014681  0.394269\n",
       "                 5.0        10.0      0.162471  0.223495\n",
       "                 10.0       15.0     -0.412240  0.413294\n",
       "                 15.0       20.0     -0.089480  0.528132\n",
       "                 20.0       25.0     -0.214247  0.450105"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, _, _ = model.predict(audio_files)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping prediction clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>classA</th>\n",
       "      <th>classB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">./1min_audio.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>-0.014681</td>\n",
       "      <td>0.394269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <th>7.5</th>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.306112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.162471</td>\n",
       "      <td>0.223495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.5</th>\n",
       "      <th>12.5</th>\n",
       "      <td>-0.327899</td>\n",
       "      <td>0.408404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>15.0</th>\n",
       "      <td>-0.412240</td>\n",
       "      <td>0.413294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        classA    classB\n",
       "file             start_time end_time                    \n",
       "./1min_audio.wav 0.0        5.0      -0.014681  0.394269\n",
       "                 2.5        7.5       0.055817  0.306112\n",
       "                 5.0        10.0      0.162471  0.223495\n",
       "                 7.5        12.5     -0.327899  0.408404\n",
       "                 10.0       15.0     -0.412240  0.413294"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, _, _ = model.predict(audio_files, overlap_fraction=0.5)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using models from older OpenSoundscape versions\n",
    "\n",
    "### Models from OpenSoundscape 0.4.x and 0.5.x\n",
    "Models trained and saved with OpenSoundscape versions 0.4.x and 0.5.x need to be loaded in a different way, and require that you know the architecture of the saved model.\n",
    "\n",
    "For example, one set of our publicly availably [binary models for 500 species](https://pitt.app.box.com/s/3048856qbm9x55yi3zfksa3fide5uuf4) was created with an older version of OpenSoundscape. These models require a little bit of manipulation to load into OpenSoundscape 0.5.x and onward. \n",
    "\n",
    "First, let's download one of these models (it's stored in a .tar format) and save it to the same directory as this notebook in a file called `opso_04_model_acanthis-flammea.tar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     8    0     8    0     0      6      0 --:--:--  0:00:01 --:--:--     0\n",
      "100 42.9M  100 42.9M    0     0  5055k      0  0:00:08  0:00:08 --:--:-- 9454k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['curl', 'https://pitt.box.com/shared/static/lglpty35omjhmq6cdz8cfudm43nn2t9f.tar', '-L', '-o', 'opso_04_model_acanthis-flammea.tar'], returncode=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['curl',\n",
    "               'https://pitt.box.com/shared/static/lglpty35omjhmq6cdz8cfudm43nn2t9f.tar', \n",
    "                '-L', '-o', 'opso_04_model_acanthis-flammea.tar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using torch.load() we can access the contents of the saved model as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_loss', 'train_accuracy', 'train_precision', 'train_recall', 'train_f1', 'train_confusion_matrix', 'valid_accuracy', 'valid_precision', 'valid_recall', 'valid_f1', 'valid_confusion_matrix', 'model_state_dict', 'optimizer_state_dict', 'labels_yaml', 'train_scores', 'train_targets', 'valid_scores', 'valid_targets'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load('./opso_04_model_acanthis-flammea.tar')\n",
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we'll need from the saved model is a list of classes. Here's how we can extract that from models saved in older opso versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acanthis-flammea-absent', 'acanthis-flammea-present']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of classes\n",
    "if \"classes\" in model_dict:\n",
    "    classes = model_dict[\"classes\"]\n",
    "elif \"labels_yaml\" in model_dict:\n",
    "    import yaml\n",
    "\n",
    "    classes = list(yaml.safe_load(model_dict[\"labels_yaml\"]).values())\n",
    "else:\n",
    "    raise ValueError(\"Could not get a list of classes from the saved model.\")\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the model notes page, we know that this is a single-target model with a resnet18 architecture trained on 5 second files. Let's create a CNN object then load the saved weights: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN('resnet18',classes,sample_duration=5.0)\n",
    "model.network.load_state_dict(model_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now fully compatible with OpenSoundscape, and can be used as above. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acanthis-flammea-absent</th>\n",
       "      <th>acanthis-flammea-present</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">./1min_audio.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>2.994287</td>\n",
       "      <td>-3.261499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "      <td>3.646061</td>\n",
       "      <td>-3.892005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>15.0</th>\n",
       "      <td>3.004456</td>\n",
       "      <td>-2.484303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <th>20.0</th>\n",
       "      <td>3.158881</td>\n",
       "      <td>-3.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <th>25.0</th>\n",
       "      <td>2.755805</td>\n",
       "      <td>-2.693598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      acanthis-flammea-absent  \\\n",
       "file             start_time end_time                            \n",
       "./1min_audio.wav 0.0        5.0                      2.994287   \n",
       "                 5.0        10.0                     3.646061   \n",
       "                 10.0       15.0                     3.004456   \n",
       "                 15.0       20.0                     3.158881   \n",
       "                 20.0       25.0                     2.755805   \n",
       "\n",
       "                                      acanthis-flammea-present  \n",
       "file             start_time end_time                            \n",
       "./1min_audio.wav 0.0        5.0                      -3.261499  \n",
       "                 5.0        10.0                     -3.892005  \n",
       "                 10.0       15.0                     -2.484303  \n",
       "                 15.0       20.0                     -3.852344  \n",
       "                 20.0       25.0                     -2.693598  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, _, _ = model.predict(audio_files)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models from OpenSoundscape 0.6.x\n",
    "\n",
    "If you saved a model with OpenSoundscape 0.6.x and want to use it in 0.7.0 or above, you will need to re-load the model using the original OpenSoundscape version that it was created with and save the model's weights explicitly:\n",
    "\n",
    "```\n",
    "#OpenSoundscape version 0.6.x\n",
    "model = load_model('/path/to/saved.model')\n",
    "\n",
    "dict_to_save = {\n",
    "    'network_state_dict':model.network.state_dict(),\n",
    "    'classes': model.classes,\n",
    "    '\n",
    "}\n",
    "torch.save(dict_to_save, '/path/to/model_dict.pt')\n",
    "```\n",
    "\n",
    "Then, you will be able to create a new model object in OpenSoundscape 0.7.0 and load the weights from the state dict as demonstrated above. Make sure to specify the correct architecture and sample duration when you create the CNN object. \n",
    "```\n",
    "#newer OpenSoundscape version\n",
    "model_dict = torch.load('/path/to/model_dict.pt')\n",
    "classes = model_dict[\"classes\"]\n",
    "\n",
    "architecture = 'resnet18' #match this with the original model!\n",
    "\n",
    "sample_duration = 5.0 #match this with the original model!\n",
    "\n",
    "model = CNN('resnet18',classes,sample_duration)\n",
    "model.network.load_state_dict(model_dict['network_state_dict'])\n",
    "```\n",
    "\n",
    "OpenSoundscape 0.7.0 now includes helper functions .save_weights() and .load_weights() which allow you to save and load platform/class independent dictionaries for increased flexibility. We recommend saving both the full model object (`.save()`) and the raw weights (`.save_weights()`) for models you plan to use in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above returns the raw predictions of the model without any post-processing (such as a softmax layer or a sigmoid layer). \n",
    "\n",
    "For details on how to use the `predict()` function for post-processing of predictions and to generate binary 0/1 predictions of class presence, see the \"Basic training and prediction with CNNs\" tutorial notebook. But, as a quick example here, let's add a softmax layer to make the prediction scores for both classes sum to 1. We can also use the `binary_preds` argument to generate 0/1 predictions for each sample and class. For presence/absence models, use the option `binary_preds='single_target'`. For multi-class models, think about whether each clip should be labeled with only one class (single target) or whether each clip could contain multiple classes (`binary_preds='multi_target'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, binary_predictions, _ = model.predict(\n",
    "    audio_files,\n",
    "    activation_layer='softmax',\n",
    "    binary_preds='single_target'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the `scores` are continuous variables, but now have been softmaxed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acanthis-flammea-absent</th>\n",
       "      <th>acanthis-flammea-present</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">./1min_audio.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.998084</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.999468</td>\n",
       "      <td>0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>15.0</th>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.004116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <th>20.0</th>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <th>25.0</th>\n",
       "      <td>0.995719</td>\n",
       "      <td>0.004280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      acanthis-flammea-absent  \\\n",
       "file             start_time end_time                            \n",
       "./1min_audio.wav 0.0        5.0                      0.998084   \n",
       "                 5.0        10.0                     0.999468   \n",
       "                 10.0       15.0                     0.995884   \n",
       "                 15.0       20.0                     0.999099   \n",
       "                 20.0       25.0                     0.995719   \n",
       "\n",
       "                                      acanthis-flammea-present  \n",
       "file             start_time end_time                            \n",
       "./1min_audio.wav 0.0        5.0                       0.001916  \n",
       "                 5.0        10.0                      0.000532  \n",
       "                 10.0       15.0                      0.004116  \n",
       "                 15.0       20.0                      0.000901  \n",
       "                 20.0       25.0                      0.004280  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have an additional output, the binary 0/1 (\"absent\" vs \"present\") predictions generated by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acanthis-flammea-absent</th>\n",
       "      <th>acanthis-flammea-present</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">./1min_audio.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>15.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <th>20.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <th>25.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      acanthis-flammea-absent  \\\n",
       "file             start_time end_time                            \n",
       "./1min_audio.wav 0.0        5.0                           1.0   \n",
       "                 5.0        10.0                          1.0   \n",
       "                 10.0       15.0                          1.0   \n",
       "                 15.0       20.0                          1.0   \n",
       "                 20.0       25.0                          1.0   \n",
       "\n",
       "                                      acanthis-flammea-present  \n",
       "file             start_time end_time                            \n",
       "./1min_audio.wav 0.0        5.0                            0.0  \n",
       "                 5.0        10.0                           0.0  \n",
       "                 10.0       15.0                           0.0  \n",
       "                 15.0       20.0                           0.0  \n",
       "                 20.0       25.0                           0.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sometimes helpful to look at a histogram of the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 316,
       "width": 874
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(scores['acanthis-flammea-present'],bins=20)\n",
    "_ = plt.xlabel('softmax score for class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up: delete model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1min_audio.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l5/32pm1n6930l_kp8qmm0gfh100000gp/T/ipykernel_10406/3219177358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1min_audio.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/opso_dev/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36munlink\u001b[0;34m(self, missing_ok)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmissing_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1min_audio.wav'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for p in Path('.').glob('*.model'):\n",
    "    p.unlink()\n",
    "for p in Path('.').glob('*.tar'):\n",
    "    p.unlink()\n",
    "Path('1min_audio.wav').unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso_dev",
   "language": "python",
   "name": "opso_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
